{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import scrublet as scr\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=14)\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = \"Ramachandran\"\n",
    "data_dir = \"/opt/datastore/aiakovliev/liver\"\n",
    "input_dir = os.path.join(data_dir, study)\n",
    "file_list = os.path.join(input_dir, \"metadata.txt\")\n",
    "sample_dirs = set(pd.read_csv(file_list)[\"sample.dir\"].tolist())\n",
    "print(sample_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = sample_dirs[0]\n",
    "print(this_dir)\n",
    "# load count matrix in mtx format\n",
    "counts_matrix = sc.read_10x_mtx(\n",
    "    this_dir,  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',   # use gene symbols for the variable names (genes)\n",
    "    cache=True                 # cache the data\n",
    ")\n",
    "# alternatively laod count matrix in h5 format (if available)\n",
    "if False: \n",
    "    counts_matrix = sc.read_10x_h5(this_dir)\n",
    "print(counts_matrix.__class__.__name__)\n",
    "# counts_matrix = sc.read_10x_h5(os.path.join(this_dir, \"matrix.mtx\"))\n",
    "#counts_matrix = scipy.io.mmread(input_dir + '/matrix.mtx').T.tocsc()\n",
    "#genes = np.array(scr.load_genes(input_dir + '/features.tsv', delimiter='\\t', column=1))\n",
    "#print('Counts matrix shape: {} rows, {} columns'.format(counts_matrix.shape[0], counts_matrix.shape[1]))\n",
    "#print('Number of genes in gene list: {}'.format(len(genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doublet rates in 1000 cells normally ~0.8% per 1k cells\n",
    "edr = 0.008\n",
    "expected_doublet_rate = float(edr)*counts_matrix.shape[0]/1000\n",
    "print('EDR: {}'.format(expected_doublet_rate))\n",
    "scrub = scr.Scrublet(counts_matrix.X, expected_doublet_rate = float(expected_doublet_rate))\n",
    "doublet_scores, predicted_doublets = scrub.scrub_doublets(min_counts=2,\n",
    "                                                          min_cells=3, \n",
    "                                                          min_gene_variability_pctl=60, \n",
    "                                                          n_prin_comps=30,\n",
    "                                                          log_transform=True,\n",
    "                                                          mean_center=True,\n",
    "                                                          normalize_variance=True,\n",
    "                                                          synthetic_doublet_umi_subsampling = 1)\n",
    "# after examining the bimodal distribution by eye, insert the threshold here\n",
    "scrub.call_doublets(threshold=0.20)\n",
    "scrub.plot_histogram()\n",
    "\n",
    "outf1 = this_dir + \"/scrublet_EDR\" + str(edr) + \"_DoubletScores.csv\"\n",
    "outf2 = this_dir + \"/scrublet_EDR\" + str(edr) + \"_PredictedDoublets.csv\"\n",
    "np.savetxt(outf1, doublet_scores, delimiter=',')\n",
    "np.savetxt(outf2, predicted_doublets, delimiter=',')\n",
    "print(\"Saved \" + outf1)\n",
    "print(\"Saved \" + outf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sample_dirs:\n",
    "    outf1 = s + \"/scrublet_EDR\" + str(edr) + \"_DoubletScores.csv\"\n",
    "    print(outf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for s in sample_dirs:\n",
    "    \n",
    "    # load count matrix\n",
    "    if False:\n",
    "        counts_matrix=sc.read_10x_h5(s)\n",
    "\n",
    "    counts_matrix=sc.read_10x_mtx(\n",
    "        s,\n",
    "        var_names='gene_symbols',\n",
    "        cache=True\n",
    "    )\n",
    "    \n",
    "    # doublet rates in 1000 cells normally ~0.8% per 1k cells\n",
    "    edr = 0.008\n",
    "    expected_doublet_rate = float(edr)*counts_matrix.shape[0]/1000\n",
    "    print('EDR: {}'.format(expected_doublet_rate))\n",
    "    \n",
    "    scrub = scr.Scrublet(counts_matrix.X, expected_doublet_rate = float(expected_doublet_rate))\n",
    "    \n",
    "    doublet_scores, predicted_doublets = scrub.scrub_doublets(min_counts=2,\n",
    "                                                      min_cells=3, \n",
    "                                                      min_gene_variability_pctl=60, \n",
    "                                                      n_prin_comps=30,\n",
    "                                                      log_transform=True,\n",
    "                                                      mean_center=True,\n",
    "                                                      normalize_variance=True,\n",
    "                                                      synthetic_doublet_umi_subsampling = 1)\n",
    "    \n",
    "    # after examining the bimodal distribution by eye, insert the threshold here\n",
    "    scrub.call_doublets(threshold=0.20)\n",
    "    scrub.plot_histogram()\n",
    "\n",
    "    outf1 = s + \"/scrublet_EDR\" + str(edr) + \"_DoubletScores.csv\"\n",
    "    outf2 = s + \"/scrublet_EDR\" + str(edr) + \"_PredictedDoublets.csv\"\n",
    "    np.savetxt(outf1, doublet_scores, delimiter=',')\n",
    "    np.savetxt(outf2, predicted_doublets, delimiter=',')\n",
    "    print(\"Saved \" + outf1)\n",
    "    print(\"Saved \" + outf2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Check 2 of the samples that look different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load count matrix\n",
    "counts_matrix = sc.read_10x_mtx(\n",
    "    this_dir,  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',   # use gene symbols for the variable names (genes)\n",
    "    cache=True                 # cache the data\n",
    ")\n",
    "# alternatively laod count matrix in h5 format (if available)\n",
    "if False: \n",
    "    counts_matrix = sc.read_10x_h5(this_dir)\n",
    "    \n",
    "# doublet rates in 1000 cells normally ~0.8% per 1k cells\n",
    "edr = 0.008\n",
    "expected_doublet_rate = float(edr)*counts_matrix.shape[0]/1000\n",
    "print('EDR: {}'.format(expected_doublet_rate))\n",
    "    \n",
    "scrub = scr.Scrublet(counts_matrix.X, expected_doublet_rate = float(expected_doublet_rate))\n",
    "    \n",
    "doublet_scores, predicted_doublets = scrub.scrub_doublets(min_counts=2,\n",
    "                                                          min_cells=3,\n",
    "                                                          min_gene_variability_pctl=60, \n",
    "                                                          n_prin_comps=30,\n",
    "                                                          log_transform=True,\n",
    "                                                          mean_center=True,\n",
    "                                                          normalize_variance=True,\n",
    "                                                          synthetic_doublet_umi_subsampling = 1)\n",
    "    \n",
    "# after examining the bimodal distribution by eye, insert the threshold here\n",
    "scrub.call_doublets(threshold=0.2)\n",
    "scrub.plot_histogram()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
